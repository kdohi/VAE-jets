{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall keras -y\n!pip install keras==2.3.1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras \nfrom keras.models import load_model\nfrom keras.layers import (Input, Concatenate, Dense, Lambda, Reshape, Dropout, Flatten, \n                          UpSampling2D, Activation, Conv2D, Conv2DTranspose, BatchNormalization, AveragePooling2D, ZeroPadding2D, RepeatVector)\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Deconv2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import objectives\nfrom keras.utils import to_categorical\nfrom sklearn.utils import shuffle\nimport matplotlib.cm as cm\nfrom matplotlib.colors import LogNorm, Normalize\nfrom keras.losses import mse, binary_crossentropy\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport numpy\nimport h5py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = h5py.File('../input/jets-dataset/PYTHIA_JETS.hdf5', 'r')\nJETS = numpy.array(data[\"image\"][:])\n\ndata2 = h5py.File('../input/jets-dataset/PYTHIA_JETS.hdf5', 'r')\nJETS_label = numpy.array(data2[\"signal\"][:])\n\nJETS, JETS_label = shuffle(JETS, JETS_label)\n\nJETS_label = JETS_label[0:870000].reshape(870000,1)\nJETS = JETS[0:870000].reshape(870000,25,25,1)\n\nJETS[JETS <1e-3] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = load_model('../input/classifier2/11X11_CNN_LR3.h5')\nselected_layers = ['leaky_re_lu_1','leaky_re_lu_2']\nselected_weights = [1, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, Y_train, Y_test = train_test_split(JETS, JETS_label, train_size=0.9)\n\nX_train = X_train.astype('float32')/100.\nX_test = X_test.astype('float32')/100.\n\nY_train = to_categorical(Y_train, num_classes = 2)\nY_test = to_categorical(Y_test, num_classes = 2)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"latent_size = 12\nbatch_size = 100\nc_space = Y_train.shape[1]\nn_epochs = 12","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = Input(shape = (25,25,1))\nlabel = Input(shape = (Y_train.shape[1],))\n\ntransform = RepeatVector(625)(label)\nlabel_2D = Reshape((25,25, Y_train.shape[1]))(transform)\ninputs = Concatenate()([image, label_2D])\n\n\nx = Conv2D(32, kernel_size = (3,3), padding = 'same')(inputs)\nx = LeakyReLU()(x)\n\nx = Conv2D(64, kernel_size = (3,3), padding = 'same', strides = 2)(x)\nx = LeakyReLU()(x)\n\nx = Conv2D(128, kernel_size = (3,3), padding = 'same', strides = 2)(x)\nx = LeakyReLU()(x)\n\nencoder_output = Flatten()(x)\n\nmu = Dense(latent_size, activation = 'linear')(encoder_output)\nsigma = Dense(latent_size, activation = 'linear')(encoder_output)\n\ndef sampling(args):\n    mu, sigma = args\n    eps = K.random_normal(shape=(batch_size, latent_size), mean=0., stddev=1.0)\n    return mu + K.exp(sigma/2.) * eps\n\nlatent_space = Lambda(sampling, output_shape=(latent_size,))([mu, sigma])\ncombined_space = Concatenate()([latent_space, label])\n\ndecoder1 = Dense((7*7*128))\ndecoder2 = Reshape((7,7,128))\n\ndecoder3 = Deconv2D(64, kernel_size = (3, 3), padding='same', strides = 2)\ndecoder4 = LeakyReLU()\n\ndecoder5 = Deconv2D(32, kernel_size = (3, 3), padding='same', strides = 2)\ndecoder6 = LeakyReLU()\n\ndecoder7 = Conv2D(1, kernel_size = (4,4), padding='valid')\n\ndecoder_out = Activation('relu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = Model(inputs = [image, label], outputs = latent_space)\nencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(latent_size + c_space, ))\n\nd = decoder1(inputs)\nd = decoder2(d)\nd = decoder3(d)\nd = decoder4(d)\nd = decoder5(d)\nd = decoder6(d)\nd = decoder7(d)\nd = decoder_out(d)\ndecoder = Model(inputs, d)\ndecoder.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d_c = decoder1(combined_space)\nd_c = decoder2(d_c)\nd_c = decoder3(d_c)\nd_c = decoder4(d_c)\nd_c = decoder5(d_c)\nd_c = decoder6(d_c)\nd_c = decoder7(d_c)\ndc_out = decoder_out(d_c)\n\nVAE = Model(inputs = [image, label], outputs = dc_out)\n\n\ndef DFC_loss(x_in, x_out):\n    kl_loss = 0.5 * K.sum(K.exp(sigma) + K.square(mu) - 1. - sigma, axis=-1)\n    return K.mean((kl_loss) + perceptual_loss(x_in,x_out) + (bce_loss(x_in, x_out)))\n\ndef bce_loss(x_in, x_out):\n    x_in = K.reshape(x_in, shape=(batch_size, 625))\n    x_out = K.reshape(x_out, shape=(batch_size, 625))\n    \n    return binary_crossentropy(x_in, x_out)\n\ndef perceptual_loss(x_in, x_out):\n    \n    x_in = K.reshape(x_in, shape=(batch_size, 25,25,1))\n    x_out = K.reshape(x_out, shape=(batch_size, 25,25,1))\n    \n    conv_outputs = [classifier.get_layer(l).output for l in selected_layers]\n    \n    activation = Model(classifier.input, conv_outputs)\n\n    h1_list = activation(x_in)\n    h2_list = activation(x_out)\n    \n    rc_loss = 0.0\n    \n    for h1, h2, weight in zip(h1_list, h2_list, selected_weights):\n        h1 = K.batch_flatten(h1)\n        h2 = K.batch_flatten(h2)\n        rc_loss = rc_loss + weight * K.sum(K.square(h1 - h2), axis=-1)\n    \n    return rc_loss\nVAE.compile(optimizer = \"adam\", loss = DFC_loss, metrics = [perceptual_loss])\nVAE.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VAE_hist = VAE.fit([X_train, Y_train], X_train, verbose = 1, batch_size=batch_size, epochs=n_epochs,\n                            validation_data = ([X_test, Y_test], X_test), callbacks = [EarlyStopping(patience = 5)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"VAE.save('Model4paper_VAE.h5')\ndecoder.save('Model4paper_decoder.h5')\nencoder.save('Model4paper_encoder.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}