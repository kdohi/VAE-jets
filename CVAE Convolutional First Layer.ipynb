{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip uninstall keras -y\n!pip install keras==2.3.1","execution_count":5,"outputs":[{"output_type":"stream","text":"Found existing installation: Keras 2.3.1\nUninstalling Keras-2.3.1:\n  Successfully uninstalled Keras-2.3.1\nCollecting keras==2.3.1\n  Using cached Keras-2.3.1-py2.py3-none-any.whl (377 kB)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.4.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.14.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.3.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (2.10.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.8)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.18.5)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.1.2)\nInstalling collected packages: keras\nSuccessfully installed keras-2.3.1\n\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras \nfrom keras.models import load_model\nfrom keras.layers import (Input, Concatenate, Dense, Lambda, Reshape, Flatten, Activation, Conv2D, RepeatVector)\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import Deconv2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras import objectives\nfrom keras.utils import to_categorical\nfrom sklearn.utils import shuffle\nfrom keras.losses import binary_crossentropy\nimport tensorflow as tf\nimport numpy\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport h5py","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load jet images and labels\ndata = h5py.File('../input/jets-dataset/PYTHIA_JETS.hdf5', 'r')\nJETS = numpy.array(data[\"image\"][:])\n\ndata2 = h5py.File('../input/jets-dataset/PYTHIA_JETS.hdf5', 'r')\nJETS_label = numpy.array(data2[\"signal\"][:])\n\nJETS, JETS_label = shuffle(JETS, JETS_label)\n\nJETS_label = JETS_label[0:870000].reshape(870000,1)\nJETS = JETS[0:870000].reshape(870000,25,25,1)\n\nJETS[JETS <1e-3] = 0","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load feature perceptual classifier and select layers\nclassifier = load_model('../input/classifier/11X11_CNN_LR.h5')\nselected_layers = ['leaky_re_lu_1','leaky_re_lu_2']\n\n# define weights for each layer in the feature perceptual loss\nselected_weights = [1, 1]","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split data into training and validation \nX_train, X_test, Y_train, Y_test = train_test_split(JETS, JETS_label, train_size=0.9)\n\n# normalize images to gray scale (0-1)\nX_train = X_train.astype('float32')/100.\nX_test = X_test.astype('float32')/100.\n\n# create categorical classes of labels\nY_train = to_categorical(Y_train, num_classes = 2)\nY_test = to_categorical(Y_test, num_classes = 2)\n\nprint(X_train.shape, Y_train.shape)\nprint(X_test.shape, Y_test.shape)","execution_count":9,"outputs":[{"output_type":"stream","text":"(783000, 25, 25, 1) (783000, 2)\n(87000, 25, 25, 1) (87000, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define basic variables such as latent size, batch size, label size, and number of epochs\nlatent_size = 12\nbatch_size = 100\nc_space = Y_train.shape[1]\nn_epochs = 12","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define image and label shape\nimage = Input(shape = (25,25,1))\nlabel = Input(shape = (Y_train.shape[1],))\n\n# tranform labels into 25x25x2 images and combine with input image\ntransform = RepeatVector(625)(label)\nlabel_2D = Reshape((25,25, Y_train.shape[1]))(transform)\ninputs = Concatenate()([image, label_2D])\n\nx = Conv2D(32, kernel_size = (3,3), padding = 'same')(inputs)\nx = LeakyReLU()(x)\n\nx = Conv2D(64, kernel_size = (3,3), padding = 'same', strides = 2)(x)\nx = LeakyReLU()(x)\n\nx = Conv2D(128, kernel_size = (3,3), padding = 'same', strides = 2)(x)\nx = LeakyReLU()(x)\n\nencoder_output = Flatten()(x)\n\nmu = Dense(latent_size, activation = 'linear')(encoder_output)\nsigma = Dense(latent_size, activation = 'linear')(encoder_output)\n\n# sampling layer\ndef sampling(args):\n    mu, sigma = args\n    eps = K.random_normal(shape=(batch_size, latent_size), mean=0., stddev=1.0)\n    return mu + K.exp(sigma/2.) * eps\n\nlatent_space = Lambda(sampling, output_shape=(latent_size,))([mu, sigma])\n\n# combine label to latent space\ncombined_space = Concatenate()([latent_space, label])\n\ndecoder1 = Dense((7*7*128))\ndecoder2 = Reshape((7,7,128))\n\ndecoder3 = Deconv2D(64, kernel_size = (3, 3), padding='same', strides = 2)\ndecoder4 = LeakyReLU()\n\ndecoder5 = Deconv2D(32, kernel_size = (3, 3), padding='same', strides = 2)\ndecoder6 = LeakyReLU()\n\ndecoder7 = Conv2D(1, kernel_size = (4,4), padding='valid')\n\ndecoder_out = Activation('relu')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# encoder\nencoder = Model(inputs = [image, label], outputs = latent_space)\nencoder.summary()","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"model_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 2)            0                                            \n__________________________________________________________________________________________________\nrepeat_vector_1 (RepeatVector)  (None, 625, 2)       0           input_2[0][0]                    \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            (None, 25, 25, 1)    0                                            \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 25, 25, 2)    0           repeat_vector_1[0][0]            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 25, 25, 3)    0           input_1[0][0]                    \n                                                                 reshape_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 25, 25, 32)   896         concatenate_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 25, 25, 32)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 13, 13, 64)   18496       leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 13, 13, 64)   0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 7, 7, 128)    73856       leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 128)    0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 6272)         0           leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 12)           75276       flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 12)           75276       flatten_1[0][0]                  \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 12)           0           dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n==================================================================================================\nTotal params: 243,800\nTrainable params: 243,800\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# decoder\ninputs = Input(shape=(latent_size + c_space, ))\n\nd = decoder1(inputs)\nd = decoder2(d)\nd = decoder3(d)\nd = decoder4(d)\nd = decoder5(d)\nd = decoder6(d)\nd = decoder7(d)\nd = decoder_out(d)\ndecoder = Model(inputs, d)\ndecoder.summary()","execution_count":13,"outputs":[{"output_type":"stream","text":"Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         (None, 14)                0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 6272)              94080     \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 7, 7, 128)         0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 14, 14, 64)        73792     \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 28, 28, 32)        18464     \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 28, 28, 32)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 25, 25, 1)         513       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 25, 25, 1)         0         \n=================================================================\nTotal params: 186,849\nTrainable params: 186,849\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define VAE losses \n\n# total loss\ndef DFC_loss(x_in, x_out):\n    kl_loss = 0.5 * K.sum(K.exp(sigma) + K.square(mu) - 1. - sigma, axis=-1)\n    return K.mean(kl_loss + feature_perceptual(x_in,x_out) + bce_loss(x_in, x_out))\n\n# Bernoulli loss \ndef bce_loss(x_in, x_out):\n    x_in = K.reshape(x_in, shape=(batch_size, 625))\n    x_out = K.reshape(x_out, shape=(batch_size, 625))\n    \n    return binary_crossentropy(x_in, x_out)\n\n# feature perceptual loss\ndef feature_perceptual(x_in, x_out):\n    \n    x_in = K.reshape(x_in, shape=(batch_size, 25,25,1))\n    x_out = K.reshape(x_out, shape=(batch_size, 25,25,1))\n    \n    conv_outputs = [classifier.get_layer(l).output for l in selected_layers]\n    activation = Model(classifier.input, conv_outputs)\n    list_1 = activation(x_in)\n    list_2 = activation(x_out)\n    \n    for calc1, calc2, weight in zip(list_1, list_2, selected_weights):\n        calc1 = K.batch_flatten(calc1)\n        calc2 = K.batch_flatten(calc2)\n        dfc_loss = weight * K.sum(K.square(calc1 - calc2), axis=-1)\n    \n    return dfc_loss","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# VAE\nd_c = decoder1(combined_space)\nd_c = decoder2(d_c)\nd_c = decoder3(d_c)\nd_c = decoder4(d_c)\nd_c = decoder5(d_c)\nd_c = decoder6(d_c)\nd_c = decoder7(d_c)\ndc_out = decoder_out(d_c)\n\nVAE = Model(inputs = [image, label], outputs = dc_out)\nVAE.compile(optimizer = \"adam\", loss = DFC_loss, metrics = [feature_perceptual])\nVAE.summary()","execution_count":15,"outputs":[{"output_type":"stream","text":"Model: \"model_3\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 2)            0                                            \n__________________________________________________________________________________________________\nrepeat_vector_1 (RepeatVector)  (None, 625, 2)       0           input_2[0][0]                    \n__________________________________________________________________________________________________\ninput_1 (InputLayer)            (None, 25, 25, 1)    0                                            \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 25, 25, 2)    0           repeat_vector_1[0][0]            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 25, 25, 3)    0           input_1[0][0]                    \n                                                                 reshape_1[0][0]                  \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 25, 25, 32)   896         concatenate_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 25, 25, 32)   0           conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 13, 13, 64)   18496       leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 13, 13, 64)   0           conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 7, 7, 128)    73856       leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 7, 7, 128)    0           conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nflatten_1 (Flatten)             (None, 6272)         0           leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 12)           75276       flatten_1[0][0]                  \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 12)           75276       flatten_1[0][0]                  \n__________________________________________________________________________________________________\nlambda_1 (Lambda)               (None, 12)           0           dense_1[0][0]                    \n                                                                 dense_2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 14)           0           lambda_1[0][0]                   \n                                                                 input_2[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 6272)         94080       concatenate_2[0][0]              \n__________________________________________________________________________________________________\nreshape_2 (Reshape)             (None, 7, 7, 128)    0           dense_3[1][0]                    \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 14, 14, 64)   73792       reshape_2[1][0]                  \n__________________________________________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)       (None, 14, 14, 64)   0           conv2d_transpose_1[1][0]         \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 28, 28, 32)   18464       leaky_re_lu_4[1][0]              \n__________________________________________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)       (None, 28, 28, 32)   0           conv2d_transpose_2[1][0]         \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 25, 25, 1)    513         leaky_re_lu_5[1][0]              \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 25, 25, 1)    0           conv2d_4[1][0]                   \n==================================================================================================\nTotal params: 430,649\nTrainable params: 430,649\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"VAE_hist = VAE.fit([X_train, Y_train], X_train, verbose = 1, batch_size=batch_size, epochs=n_epochs,\n                            validation_data = ([X_test, Y_test], X_test), callbacks = [EarlyStopping(patience = 5)])","execution_count":16,"outputs":[{"output_type":"stream","text":"Train on 783000 samples, validate on 87000 samples\nEpoch 1/12\n783000/783000 [==============================] - 102s 131us/step - loss: 62.0653 - feature_perceptual: 43.2174 - val_loss: 48.7052 - val_feature_perceptual: 29.2457\nEpoch 2/12\n783000/783000 [==============================] - 97s 123us/step - loss: 48.1041 - feature_perceptual: 29.1628 - val_loss: 46.6397 - val_feature_perceptual: 27.4947\nEpoch 3/12\n783000/783000 [==============================] - 97s 124us/step - loss: 46.8938 - feature_perceptual: 28.0579 - val_loss: 46.6437 - val_feature_perceptual: 27.6925\nEpoch 4/12\n783000/783000 [==============================] - 96s 123us/step - loss: 46.2585 - feature_perceptual: 27.4668 - val_loss: 46.3139 - val_feature_perceptual: 27.8505\nEpoch 5/12\n783000/783000 [==============================] - 96s 123us/step - loss: 45.8699 - feature_perceptual: 27.0995 - val_loss: 46.3854 - val_feature_perceptual: 27.2695\nEpoch 6/12\n783000/783000 [==============================] - 96s 123us/step - loss: 45.5698 - feature_perceptual: 26.8165 - val_loss: 45.5315 - val_feature_perceptual: 26.5897\nEpoch 7/12\n783000/783000 [==============================] - 96s 123us/step - loss: 45.3736 - feature_perceptual: 26.6358 - val_loss: 45.3767 - val_feature_perceptual: 26.5319\nEpoch 8/12\n783000/783000 [==============================] - 96s 122us/step - loss: 45.1934 - feature_perceptual: 26.4604 - val_loss: 45.1733 - val_feature_perceptual: 26.6255\nEpoch 9/12\n783000/783000 [==============================] - 97s 123us/step - loss: 45.0791 - feature_perceptual: 26.3612 - val_loss: 44.5957 - val_feature_perceptual: 25.8055\nEpoch 10/12\n783000/783000 [==============================] - 97s 124us/step - loss: 44.9422 - feature_perceptual: 26.2289 - val_loss: 45.0519 - val_feature_perceptual: 26.0596\nEpoch 11/12\n783000/783000 [==============================] - 96s 123us/step - loss: 44.8479 - feature_perceptual: 26.1376 - val_loss: 44.8257 - val_feature_perceptual: 26.2142\nEpoch 12/12\n783000/783000 [==============================] - 96s 123us/step - loss: 44.7696 - feature_perceptual: 26.0702 - val_loss: 44.7651 - val_feature_perceptual: 25.9402\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"VAE.save('Model4paper_VAE.h5')\ndecoder.save('Model4paper_decoder.h5')\nencoder.save('Model4paper_encoder.h5')","execution_count":17,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}